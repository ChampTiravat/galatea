!obj:pylearn2.train.Train {
    dataset: &train  !pkl: "/data/lisatmp/goodfeli/esp_bow.pkl",
    model: !obj:galatea.dbm.inpaint.super_dbm.SuperDBM {
              batch_size : 100,
              niter: 6, #note: since we have to backprop through the whole thing, this does
                         #increase the memory usage
              visible_layer: !obj:galatea.dbm.inpaint.super_dbm.BinaryVisLayer {
                nvis: 4000,
                bias_from_marginals: *train,
              },
              hidden_layers: [
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                        detector_layer_dim: 4500,
                        pool_size: 1,
                        irange: .015,
                        layer_name: 'h0',
                        init_bias: -2.
               }
              ]
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
               learning_rate: 1e-03,
               init_momentum: .5,
               monitoring_dataset : {
                        'train': *train,
               },
               monitoring_batches: 10,
               cost: !obj:pylearn2.costs.cost.SumOfCosts {
                       costs :[
                               !obj:pylearn2.costs.dbm.VariationalPCD {
                                   num_chains: 500,
                                   num_gibbs_steps: 5
                               },
                               !obj:pylearn2.costs.dbm.TorontoSparsity {
                                    coeffs: [ 1. ],
                                    targets: [ .1],
                                    supervised: 0
                               },
                               !obj:galatea.dbm.inpaint.super_dbm.DBM_WeightDecay {
                                        coeffs: [ .0000005 ]
                               }
                       ]
               },
               monitoring_costs: {
                   'vsgpl' : !obj:galatea.dbm.inpaint.super_inpaint.SuperInpaint {
                                       supervised: 0,
                                       mask_gen : !obj:galatea.dbm.inpaint.super_inpaint.MaskGen {
                                                drop_prob: 0.5,
                                                sync_channels: 0
                                       },
                               },
               },
               update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {
                    decay_factor: 1.0000004,
                    min_lr: 0.00001
               }
        },
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq : 1
}

