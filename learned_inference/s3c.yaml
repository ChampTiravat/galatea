!obj:pylearn2.train.Train {
    dataset: &src !obj:pylearn2.datasets.zca_dataset.ZCA_Dataset {
        convert_to_one_hot: 0,
        preprocessor: !pkl: "/data/lisatmp/goodfeli/cifar10_preprocessed_pipeline_2M_6x6.pkl",
        preprocessed_dataset: !pkl: "/data/lisatmp/goodfeli/cifar10_preprocessed_train_2M_6x6.pkl", 
        start: &valid_stop 1000,
        stop: 2000000
    },
    model: !obj:galatea.s3c.s3c.S3C {
               nvis : 108,
               nhid : 1600,
               init_bias_hid : -4.,
               max_bias_hid : 0.,
               min_bias_hid : -7.,
               irange  : .02,
               constrain_W_norm : 1,
               init_B  : 3.,
               min_B   : .1,
               max_B   : 1e6,
               tied_B :  0,
               init_alpha : 1.,
               min_alpha : 1e-3,
               max_alpha : 1e6,
               init_mu : 0.,
               random_patches_src : *src,
               #"min_mu"  : 1.,
               #"max_mu"  : 1.,
               #"recycle_q" : 1000,
               "monitor_functional" : 1,
               "monitor_params" : [ 'B', 'p', 'alpha', 'mu', 'W' ],
               #"monitor_stats" : [ 'mean_h', 'mean_hs', 'mean_sq_s', 'mean_sq_hs' ],
               "e_step" : !obj:pylearn2.models.s3c.E_Step {
                        "h_new_coeff_schedule" : [ .1, .1, .1, .1, .1, .1, .1, .1, .2, .2, .2, .3, .3, .3, .4, .4, .4, .4, .4 ],
                        s_new_coeff_schedule : [  .7, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1, .1 ],
                        clip_reflections : 1,
                        #"monitor_em_functional" : 1
               },
               m_step     : !obj:pylearn2.models.s3c.Grad_M_Step {
                        learning_rate : 1e-2,
                        B_learning_rate_scale : 1.,
                        W_learning_rate_scale : 10.,
                        p_penalty : 1.,
                        B_penalty : 1.,
                        alpha_penalty : 1.
               },
        },
    algorithm: !obj:pylearn2.training_algorithms.default.DefaultTrainingAlgorithm {
        batch_size : 100,
       batches_per_iter : 1000,
       monitoring_batches: 10,
       monitoring_dataset :  !obj:pylearn2.datasets.zca_dataset.ZCA_Dataset {
        convert_to_one_hot: 0,
        preprocessor: !pkl: "/data/lisatmp/goodfeli/cifar10_preprocessed_pipeline_2M_6x6.pkl",
        preprocessed_dataset: !pkl: "/data/lisatmp/goodfeli/cifar10_preprocessed_train_2M_6x6.pkl", 
        start: 0,
        stop: *valid_stop
        },
       termination_criterion: !obj:pylearn2.scripts.icml_2013_wrepl.black_box.terminate.Terminate {
        }
    },
    save_path: "${PYLEARN2_TRAIN_FILE_NAME}.pkl",
    save_freq : 1,
}

