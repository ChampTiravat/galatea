!obj:pylearn2.scripts.train.Train {
    dataset: &data !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        shuffle: 1,
        binarize: 1
    },
    model: !obj:galatea.dbm.inpaint.super_dbm.SuperDBM {
              batch_size : 3000,
              niter: 6, #note: since we have to backprop through the whole thing, this does
                         #increase the memory usage
              visible_layer: !obj:galatea.dbm.inpaint.super_dbm.BinaryVisLayer {
                nvis: 784,
                bias_from_marginals: *data,
              },
              hidden_layers: [
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                        detector_layer_dim: 500,
                        pool_size: 1,
                        irange: 0.05,
                        layer_name: 'h0',
                        init_bias: 0.
               },
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                        detector_layer_dim: 1000,
                        pool_size: 1,
                        irange: 0.05,
                        layer_name: 'h1',
                        init_bias: 0.
               }
              ]
    },
    algorithm: !obj:galatea.dbm.inpaint.inpaint_alg.InpaintAlgorithm {
               batches_per_iter : 10,
               monitoring_batches : 1,
               monitoring_dataset : *data,
               init_alpha : [0.0256, .128, .256, 1.28, 2.56],
               reset_alpha: 0,
               max_iter: 5,
               cost : !obj:galatea.dbm.inpaint.super_inpaint.SuperInpaint {
                both_directions : 1,
                l1_act_targets: [ [.1, .02], [.1, .02]  ],
                l1_act_coeffs: [ [.05, .05], [.05, .05]  ],
                noise : 1
               },
               mask_gen : !obj:galatea.dbm.inpaint.super_inpaint.MaskGen {
                        drop_prob: 0.5,
                        balance: 0,
                        sync_channels: 0
               }
        },
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq : 1
}

