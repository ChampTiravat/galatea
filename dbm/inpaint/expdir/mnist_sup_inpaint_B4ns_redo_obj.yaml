# redo B4ns training, this time using the entire train set. train until the 
# objective on the train set as a whole is the same as it was on just the
# first 50k last time
!obj:pylearn2.scripts.train.Train {
    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        binarize: 1,
        one_hot: 1,
    },
    model: !obj:galatea.dbm.inpaint.super_dbm.SuperDBM {
              batch_size : 1250,
              niter: 6, #note: since we have to backprop through the whole thing, this does
                         #increase the memory usage
              visible_layer: !obj:galatea.dbm.inpaint.super_dbm.BinaryVisLayer {
                nvis: 784,
                bias_from_marginals: *train,
              },
              hidden_layers: [
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                        detector_layer_dim: 500,
                        pool_size: 1,
                        irange: 0.05,
                        layer_name: 'h0',
                        init_bias: 0.
               },
                !obj:galatea.dbm.inpaint.super_dbm.DenseMaxPool {
                        detector_layer_dim: 1000,
                        pool_size: 1,
                        irange: 0.05,
                        layer_name: 'h1',
                        init_bias: 0.
               },
               !obj:galatea.dbm.inpaint.super_dbm.Softmax {
                        irange: .03,
                        layer_name: 'c',
                        n_classes: 10
               }
              ]
    },
    algorithm: !obj:galatea.dbm.inpaint.inpaint_alg.InpaintAlgorithm {
               monitoring_dataset : {
                        'train': *train
               },
               line_search_mode: 'exhaustive',
               init_alpha : [0.0256, .128, .256, 1.28, 2.56],
               reset_alpha: 0,
               conjugate: 1,
               reset_conjugate: 0,
               max_iter: 5,
               cost: !obj:pylearn2.costs.cost.SumOfCosts {
                       costs :[
                               !obj:galatea.dbm.inpaint.super_dbm.MF_L1_ActCost
                               {
                                        targets: [  .06, .06, 0. ],
                                        eps:     [  .04,  .04, 0. ],
                                        coeffs:  [ .01,  .01, 0.  ]
                               },
                               !obj:galatea.dbm.inpaint.super_inpaint.SuperInpaint {
                                        both_directions : 0,
                                        noise : 0,
                                        supervised: 1
                               }
                       ]
               },
               mask_gen : !obj:galatea.dbm.inpaint.super_inpaint.MaskGen {
                        drop_prob: 0.5,
                        balance: 0,
                        sync_channels: 0
               },
               termination_criterion: !obj:pylearn2.termination_criteria.ChannelTarget
               {
                        channel_name: "train_objective",
                        target: 0.0390425473452
               }
        },
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq : 1
}

