# Use column norm constraints instead of weight decay
!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.binarizer.Binarizer {
      raw: &raw_train !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        shuffle: 0,
        one_hot: 1,
    }},
    model: !obj:pylearn2.monitor.push_monitor {
        model: !pkl: "expdir/mnist_sup_inpaint_X3L2B_best.pkl",
        name: "monitor_first"
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        monitoring_dataset : {
            # 'train': *train,
            valid: !obj:pylearn2.datasets.binarizer.Binarizer {
                raw: &raw_valid !obj:pylearn2.datasets.mnist.MNIST {
                                which_set: "train",
                                shuffle: 0,
                                one_hot: 1,
                                start: 50000,
                                stop: 60000
                            }},
                        'raw_valid': *raw_valid,
                        'raw_test': !obj:pylearn2.datasets.mnist.MNIST {
                                which_set: "test",
                                shuffle: 0,
                                one_hot: 1,
                            }
               },
               learning_rate: .5,
               init_momentum: .6,
               cost: !obj:pylearn2.costs.cost.SumOfCosts {
                       costs :[
                               !obj:galatea.dbm.inpaint.super_inpaint.SuperInpaint {
                                    monitor_multi_inference: 1,
                                        both_directions : 0,
                                        noise : 0,
                                        supervised: 1,
                                        l1_act_targets: [  .06, .07, 0. ],
                                        l1_act_eps:     [  .04,  .05, 0. ],
                                        l1_act_coeffs:  [ .01,  .0001, 0.  ],
                                       mask_gen : !obj:galatea.dbm.inpaint.super_inpaint.MaskGen {
                                                drop_prob: 0.5,
                                                balance: 0,
                                                sync_channels: 0
                                       },
                               },
                               #!obj:galatea.dbm.inpaint.super_dbm.DBM_WeightDecay {
                               #         coeffs: [ .0000005, .0000005, .0000005 ]
                               #}
                       ]
               },
               termination_criterion: !obj:pylearn2.termination_criteria.EpochCounter
               {
                   max_epochs: 100
               }
        },
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq : 1
}

