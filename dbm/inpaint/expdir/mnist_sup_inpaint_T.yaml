# Like mnist_sup_inpaint_PWr6new, but rerun after fixing a bug in Softmax.recons_cost
# where it failed to take the log of the second term
!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        shuffle: 0,
        one_hot: 1,
        start: 0,
        stop: 50000
    },
    model: !obj:galatea.dbm.inpaint.super_dbm.SuperDBM {
              batch_size : 200,
              niter: 6, #note: since we have to backprop through the whole thing, this does
                         #increase the memory usage
              visible_layer: !obj:galatea.dbm.inpaint.super_dbm.GaussianConvolutionalVisLayer {
                rows: 28,
                cols: 28,
                channels: 1,
              },
              hidden_layers: [
                !obj:galatea.dbm.inpaint.super_dbm.ConvMaxPool {
                        border_mode: 'full',
                        output_channels: 16,
                        kernel_rows: 5,
                        kernel_cols: 5,
                        pool_rows: 2,
                        pool_cols: 2,
                        irange: .05,
                        layer_name: 'h0',
                        init_bias: -3.
               },
                !obj:galatea.dbm.inpaint.super_dbm.ConvMaxPool {
                        border_mode: 'full',
                        output_channels: 32,
                        kernel_rows: 5,
                        kernel_cols: 5,
                        pool_rows: 2,
                        pool_cols: 2,
                        irange: .05,
                        layer_name: 'h1',
                        init_bias: -3.
               },
               !obj:galatea.dbm.inpaint.super_dbm.Softmax {
                        sparse_init: 15,
                        layer_name: 'c',
                        n_classes: 10
               }
              ]
    },
    algorithm: !obj:pylearn2.training_algorithms.bgd.BGD {
        scale_step: .5,
        monitoring_batches: 5,
      batches_per_iter: 50,
      verbose_optimization: 0,
       seed: [2012, 10, 17],
       monitoring_dataset : {
                        'train': *train,
                        'valid': !obj:pylearn2.datasets.mnist.MNIST {
                                which_set: "train",
                                shuffle: 0,
                                one_hot: 1,
                                start: 50000,
                                stop: 60000
                            },
               },
               line_search_mode: 'exhaustive',
               init_alpha : [0.0256, .128, .256, 1.28, 2.56],
               reset_alpha: 0,
               conjugate: 1,
               reset_conjugate: 0,
               updates_per_batch: 5,
               cost: !obj:pylearn2.costs.cost.SumOfCosts {
                       costs :[
                               !obj:galatea.dbm.inpaint.super_inpaint.SuperInpaint {
                                        both_directions : 0,
                                        noise : 0,
                                        supervised: 1,
                                        l1_act_targets: [  [.2, .05], [.1, .025], 0. ],
                                        l1_act_eps:     [  [.1, .025],  [.05, .0125], 0. ],
                                        l1_act_coeffs:  [ [.01, .01],  [.001, .001], 0.  ],
                                       mask_gen : !obj:galatea.dbm.inpaint.super_inpaint.MaskGen {
                                                drop_prob: 0.9,
                                                balance: 0,
                                                sync_channels: 0
                                       },
                               },
                               #!obj:galatea.dbm.inpaint.super_dbm.DBM_WeightDecay {
                               #         coeffs: [ .0000005, .0000005, .0000005 ]
                               #}
                       ]
               },
               termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased
               {
                        channel_name: "valid_objective",
                        N: 15,
                        prop_decrease: 0.
               }
        },
    extensions: [
                !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
                        channel_name: "valid_err",
                        save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl"
                }
        ],
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq : 1
}

