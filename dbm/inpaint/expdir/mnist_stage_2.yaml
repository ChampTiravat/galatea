!obj:pylearn2.scripts.train.Train {
    dataset: &data !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        shuffle: 1,
        binarize: 1
    },
    # this pulls in niter / batch_size
    model: !obj:pylearn2.monitor.push_monitor {
           model: !pkl: "/u/goodfeli/galatea/dbm/inpaint/expdir/mnist_stage_1A.pkl",
           name: 'inpainting_monitor'
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
               batch_size: &batch_size 100,
               set_batch_size: 1,
               learning_rate: 1e-3,
               init_momentum: .5,
               monitoring_batches : 10,
               monitoring_dataset : *data,
               cost : !obj:galatea.dbm.inpaint.super_dbm.DBM_PCD {
                    num_chains: *batch_size,
                    num_gibbs_steps: 5
               },
        },
    callbacks: [ !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {
        final_momentum: .9,
        start: 0,
        saturate: 50
    }],
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq : 1
}

