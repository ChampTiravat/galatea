!obj:pylearn2.train.Train {
    dataset:  &train !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        binarize: 1,
        one_hot: 1,
        start: 0,
        stop: 50000
    },
    model: !obj:galatea.sample_prop.basic.SimpleModel2 {
        nvis: 784,
        num_hid: 500,
        num_hid_2: 500,
        num_class: 10,
        y_max_col_norm: 10
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
               batch_size: 100,
               set_batch_size: 1,
               learning_rate: 5e-2,
               init_momentum: .5,
               monitoring_dataset:
                                {
                                'train' : *train,
                                'valid' : !obj:pylearn2.datasets.mnist.MNIST {
                                        which_set: "train",
                                        binarize: 1,
                                        one_hot: 1,
                                        start: 50000,
                                        stop:  60000
                                        }
               },
               cost : !obj:galatea.sample_prop.basic.SamplingCost3 {
               },
               termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased
               {
                        channel_name: "valid_y_misclass",
                        N: 100,
                        prop_decrease: 0.
               }
        },
    extensions: [
    !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {
        start: 0,
        saturate: 200,
        final_momentum: .9
    },
    !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
        start: 1,
        saturate: 527,
        decay_factor: 0.006308
    },
    !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
            channel_name: "valid_y_misclass",
            save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl"
    },
    ],
    save_path: "${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl",
    save_freq : 100
}

