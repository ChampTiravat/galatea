
Say we want to find f(x) such that

E_x f_i(x) = 0
E_x f_i(x)^2 = 1
E_x f_i(x) f_j(x)^2 = 0

and we minimize the following:

E_x sum_i,j  (d f_i(x) / d x_j )^2


Let f(x) = W g(x) and let's find the optimal W.

d f_i(x) / d x_j = sum_ k ( d f_i(x) / d g_k (x) ) ( d g_k(x) / d x_j )
= sum_ k ( d f_i(x) / d g_k (x) ) ( d g_k(x) / d x_j )
= sum_ k W_ik G_kj 
where G_kj = d g_k(x) / d x_j

so we want to minimize the squared frobenius norm of 

Fro(WG)^2 = Tr( WG G^T W^T ) 

I think you just take the eigenvectors with SMALLEST eigenvalue of G G^T


procedure:
    compute g1(X), G1(X)  (note that G1 is actually a 3 tensor)
        say there is PCA preprocessing g0(X) = (X-mu0)*P

        dg0_i / d_xj = P_ji

        let J_ij = dg1_i / dg0_j

        dg1_i / d_xj = sum_k (dg1_i / dg0_k) (dg0_k / d_xj)
                     = sum_k (dg1_i / dg0_k) P_kj
                     = sum_k J_ik P_kj

        so G1 = JP

    mu = mean(g1(X))
    g2(X) = g1(X) - mu ; G2(X) = G1(X)
    compute Z = whitening matrix of g2
    G3(X) = G2(X) Z

    compute W from G3


final feature extractor is:
    (g( (X-mu0)P)-mu)ZW


    G3(X) = Z G2(X)
          = Z J P

    G = G3 G3^T

      = Z J P P^T J^T Z^T

    where P is r x n
 





WQ is of dim h x v.
Q is of dim g x v
W is of dim h x g


