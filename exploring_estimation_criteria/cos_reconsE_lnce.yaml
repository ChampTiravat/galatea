#Was in the course of translating this to use SGD instead of DefaultTrainingAlgorithm. Realized it'll be kind of complicated
#to restore since local_noise_ebm was accidentally deleted when I removed it from the public repo (I moved it into galatea,
#deleted the old class repo, then accidentally overwrote the copy in
#galatea with a git command that didn't do what I expected it to (fuck you, git), which at that time was the only copy)
#
# Also, it looks like this might not be the best script to convert, since it says "different_examples" : 1.
#
!obj:pylearn2.scripts.train.Train {
    "dataset": !obj:pylearn2.datasets.cos_dataset.CosDataset {},
    "model": !obj:galatea.models.febm.FEBM {
                "energy_function": !obj:galatea.energy_functions.scratch.recons_model_1 {
                        "nvis" : 2,
                        "nhid" : 400,
                        "init_bias_hid" : 0.0,
                        "irange"  : 2.5
                        }
                "init_noise_var"    : 2.0,
                "min_misclass"  : .05,
                "max_misclass"  : .5,
                "noise_var_scale_up" : 1.001,
                "noise_var_scale_down" : .999,
                "max_noise_var"       : 2.,
                "time_constant"  : .1,
                "learning_rate" : .0002,
                "different_examples" : 1.,
                "init_vis_prec" : 1.,
                "learn_vis_prec" : 1.,
                "vis_prec_lr_scale" : .001,
             
                "init_delta" : -0.5
        },
    "algorithm": !obj:pylearn2.training_algorithms.default.DefaultTrainingAlgorithm {
               "learning_rate" : .0002,
               "batch_size" : 5,
               "batches_per_iter" : 1000,
               "monitoring_batches" : 10,
               "monitoring_dataset" : !obj:pylearn2.datasets.cos_dataset.CosDataset {},

        },
    "save_path": "autoencoder_cos.pkl"
}

